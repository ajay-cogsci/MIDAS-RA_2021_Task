# -*- coding: utf-8 -*-
"""MIDAS-RA2021

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZOKWlmhZWRMrmjN96oMtntBqwVSmT-lk

# **TASK 3  NLP** Submission by Ajay Agarwal

## Subtask1 -  Cleaning the data
This would involve the following steps --

1. Understanding the data and performing basic EDA
2. Understanding the category tree structure
3. Finding out the maximum and minimum number of sub-categories in category tree
4. Seperating all the sub-categories
5. Finding the primary category
"""

#Let's begin by importing some basic libraries for implementing some basic ML algorithms

import pandas as pd
import numpy as np 
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn import metrics
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier

"""Note. Here, we used the parameter of error_bad_lines = False, because in a previous iteration, we encountered the following error -
 
`ParserError: Error tokenizing data. C error: Expected 15 fields in line 19219, saw 23`

This would skip only one line and results in reduction of dataset length by one instance whic doesn't affect the models
"""

#Importing the data as csv file

flipkart_data = pd.read_csv("flipkart_com-ecommerce_sample.csv" , error_bad_lines=False)

flipkart_data.head(15)

"""### Let's understand the category tree in a lexicographical manner.
---


"""

flipkart_data['product_category_tree'].unique()

"""### Notice - The category tree is made of "each category" followed by the symbol ">>" The first category begins with the symbol [" and the last category ends with the symbol "]

Utilizing this information let's build a function that would find what are the maximum and minimum number of categories possible for any entry in the dataset
"""

#Finding number of sub-categories for each row using the fact that the presence of one symbol ">>" would mean two subcategories present in the category tree

def count_category_remaining():
  count_of_category = []

  for x in range(len(flipkart_data['product_category_tree'])):
   given_tree = flipkart_data.iloc[x]["product_category_tree"]
   count = given_tree.count(">>")
   count_of_category.append(count)
  
#Printing the number of entries for each number of categories.
  from collections import Counter
  c = Counter(count_of_category)
  print(c.most_common())

count_category_remaining()

#This counter can be understood as counting logs out of a woodstick with "n" cuts. So, zero cut means there is one log. Here, zero occurences of >> means that there is one category. 
#Finally, the maximum number of occurence of >> in one row entry is 7, meaning at max there are 8 sub-categories.

"""### Notice, most of the products have either four, three or even two categories. Then, there is suddent drop to five categories products and six category products. The presence of 30 items in eight categories represents a very niched product presence.

## We can say that 
**Number of Categories is directly proportional to degree of product nicheness**

### Established this, we move ahead to seperating each category in the category tree column and adding new columsn in the dataframe for each sub-category encountered while traversing a category from left to right.
"""

#Let's try to seperate the categories in the category tree using lambda functions
#We add columns for each category we seperate in order LtoR

def remove_subcategory():
  n_category=[]
  
  for i in range(len(flipkart_data['product_category_tree'])):
   original = flipkart_data.iloc[i]['product_category_tree']


   
   sub_category = original.partition(">>")
   insert_this = sub_category[0]


   #Removing nth_category from product_category
   old_value = flipkart_data.iloc[i]['product_category_tree']
   new_value = old_value.replace(insert_this+">>","")


   flipkart_data.at[i,"product_category_tree"] = new_value

   if insert_this.startswith("[\""):

    #Appending the nth category to a list of n_category which will be returned
    n_category.append(insert_this.replace("[\"",""))
   else:
     n_category.append(insert_this)

  return n_category

#Since there are maximum eight categories in the product category tree, we create eight new columns and add the sub-category for each respectively

add_category = remove_subcategory()
flipkart_data['first_category'] = add_category

add_category = remove_subcategory()
flipkart_data['second_category'] = add_category

add_category = remove_subcategory()
flipkart_data['third_category'] = add_category

add_category = remove_subcategory()
flipkart_data['fourth_category'] = add_category

add_category = remove_subcategory()
flipkart_data['fifth_category'] = add_category

add_category = remove_subcategory()
flipkart_data['sixth_category'] = add_category

add_category = remove_subcategory()
flipkart_data['seventh_category'] = add_category


add_category = remove_subcategory()
flipkart_data['eigth_category'] = add_category

flipkart_data.head()

"""### Our primary category will be the first category column since every row instance has a not-null entry for the "first_category" column.

We shall now move ahead with Pre-Processing and Visualization

## Subtask 2(A): Data Visualization

This would involve the following steps - 

1. Removing all the columns except "description" and "first category"
2. Visualization of "first category" columns to identify category distribution
3. Assessing possibilities to manually merging "wordy" first category (that earlier had no further sub-categories) into existing parent category
4. If step 3 prevails, visualization of merged category distribution
5. If step 3 fails, dropping all such categories.
6. Wordcloud visualization for "description" column
7. Providing a statistical EDA of training dataset
8. Visualization of description length variation
"""

#Step 1. Removing all columns except "description" and "first_category"

flipkart_data.drop(flipkart_data.columns.difference(['first_category', 'description']),1, inplace= True)

flipkart_data

#Step 2: Visualization of "first category" columns to identify category distribution

import seaborn as sns
sns.set_style("darkgrid")
import matplotlib.pyplot as plt

flipkart_data['first_category'].value_counts().plot(kind='barh', figsize=(350,300))
plt.xlabel("Total")
plt.ylabel("Category")
plt.title("Product Category Distribution for given dataset",fontweight="bold", size=12);

"""Note. - We take a detour of the step 2 after realizing that there are design restrictions that possibly wont allow us to accurately read the labels. Hence, we plot a basic pie-chart instead for the same purpose."""

fig, ax = plt.subplots(1, 1, figsize=(15,15))
flipkart_data['first_category'].value_counts().plot.pie( autopct = '%1.1f%%')

"""Notice how one category entries are disrupting a peaceful visualization. Let's first check them and find out can they be manually merged. """

flipkart_data.groupby(by='first_category').size().head(20)

"""Are only 20 entries disrupting us ? If yes, then they can be manually replaced with simpler first_categories that already exist. If not, we will be coerced to drop them instead."""

flipkart_data.groupby(by='first_category').size().head(100)

"""Only 100 ? or more ?"""

flipkart_data.groupby(by='first_category').size().head(1000)

"""Notice that even after top 1000 entries were displayed in order of size, there are still more. It is manually impossible to merge these categories, hence we are coerced to drop them"""

flipkart_data = flipkart_data[flipkart_data.groupby('first_category')['first_category'].transform('count').ge(5)]

"""Let's try the pie-chart visualization again"""

fig, ax = plt.subplots(1, 1, figsize=(15,15))
flipkart_data['first_category'].value_counts().plot.pie( autopct = '%1.1f%%')

"""Much better. Let's group them on size basis to see the lowest category frequency."""

flipkart_data.groupby(by='first_category').size()

"""**It's perfect. Let's begin finding Wordcloud visualization of description column**"""

from wordcloud import WordCloud
from wordcloud import STOPWORDS


stopwords = set(STOPWORDS)

wordcloud = WordCloud(background_color='white',
                      max_words=100,
                      width=500,
                      height=500
)

wordcloud.generate(str(flipkart_data['description']))
plt.rcParams['figure.figsize'] = (8,8)
plt.axis('off')
plt.suptitle('WordCloud Visualization of Product Description', fontsize=16, fontweight='bold')
plt.imshow(wordcloud, interpolation='bilinear')
plt.show()

"""Let's move ahead with providing a statistical EDA of training dataset"""

eda_train = pd.DataFrame()

eda_train['category_len'] = flipkart_data['first_category'].apply(lambda x: len(str(x).split()))
eda_train['description_len'] = flipkart_data['description'].apply(lambda x: len(str(x).split()))

eda_train.describe()

"""Utilizing the lambda functions we used in the above cell to calculated category and description wordlength, we can now plot the same"""

x = eda_train['description_len']
sns.distplot(x)
plt.title('Number of Words in Description')
plt.show()

"""Let's find the number of words most frequently used for "description" utilizing stats from SciPy and Gaussian KDE on above Distribution Plot"""

from scipy import stats
kde = stats.gaussian_kde(x) # Compute the Gaussian KDE
idx = np.argmax(kde.pdf(x)) # Get index of peak point
plt.axvline(x[idx], color='red')

"""**Average number of words used by seller for description of a product is 31**

With this we finish visualization of our training dataset. The choice for our visualization was to gather useful insight and not just for the purposing of doing so. Further, this point no visualization would be possible. We shall now move ahead to pre-processing and training ML algorithms for our purpose.

## Subtask 2(B) Pre-processing Training Dataset

This would involve the following steps - 

1. Identification of (if any) null values
2. Training & Testing dataset split (70:30)
3. Stopword removal from Description Column
4. Tf-IDF vectorization with Pipeline formation (along with LinearSVC)

We begin with checking if there are any null values in the column
"""

flipkart_data.isnull().sum()

"""Yes. There are two categories with no description. We drop them"""

data = flipkart_data.dropna()

len(data)

"""As we mentioned in the task, the primary "product description" must be the input feature, we create X and y training datasets respectively."""

#Using 'description' as the only feature for training

X = data['description']
y = data['first_category']

"""We perform the Training & Testing dataset split (70:30)"""

#Preparing Training Data and perform train-test split

# Split the data into 70-30
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=77, shuffle=True, stratify = y)

#Checking the shape of the splitted data
print(f"Training Data Shape: {X_train.shape}")
print(f"Testing Data Shape: {X_test.shape}")

"""Moving ahead to Stopword collection and removal via NLTK library"""

# Create list of StopWords
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
stopwords = stopwords.words('english')

"""Finally, we perform Tfidf vectorization with stopwords and add the same to the pipeline"""

from sklearn.svm import LinearSVC
linear_svc = Pipeline([('tfidf', TfidfVectorizer(stop_words=stopwords)),
                           ('clf', LinearSVC())])

"""## Subtask 3: Identidication of Accuracy Metrics

We shall use the following metrics to measure accuracy of our classifier models

1. Weighted Precision
2. Weighted Recall
3. Accuracy
4. F1 score
5. Confusion Matrix

## Subtask 4. Trying various ML Classification Algorithms

We shall try the following ML classification algorithms in order - 

1. Linear Support Vector Machine
2. Naive Bayes
3. KNN
4. Random Forest
"""



linear_svc.fit(X_train, y_train)
predictions = linear_svc.predict(X_test)
# Print the overall accuracy, along with weighted precision, weighted recall and f1 scores
print("Accuracy by LinearSVC is ")
print(metrics.accuracy_score(y_test,predictions)*100)
print("Weighted Precision by LinearSVC is")
print(metrics.precision_score(y_test,predictions, average='weighted')*100)
print("Weighted Recall by LinearSVC is ")
print(metrics.recall_score(y_test,predictions, average='weighted')*100)
print("F1 score by LinearSVC is ")
print(metrics.f1_score(y_test,predictions, average='weighted')*100)

# Report the confusion matrix
print(metrics.confusion_matrix(y_test,predictions))
# Print a classification report
print(metrics.classification_report(y_test,predictions))
# Print the overall accuracy
print(metrics.accuracy_score(y_test,predictions))

"""### Naive Bayes"""

naive_bayes = Pipeline([('tfidf', TfidfVectorizer(stop_words=stopwords)),
                     ('clf', MultinomialNB())])

naive_bayes.fit(X_train, y_train) 

predictions = naive_bayes.predict(X_test)
# Print the overall accuracy, along with weighted precision, weighted recall and f1 scores
print("Accuracy by Naive Bayes is ")
print(metrics.accuracy_score(y_test,predictions)*100)
print("Weighted Precision by Naive Bayes is")
print(metrics.precision_score(y_test,predictions, average='weighted')*100)
print("Weighted Recall by Naive Bayes is ")
print(metrics.recall_score(y_test,predictions, average='weighted')*100)
print("F1 score by Naive Bayes is ")
print(metrics.f1_score(y_test,predictions, average='weighted')*100)

# Report the confusion matrix
print(metrics.confusion_matrix(y_test,predictions))
# Print a classification report
print(metrics.classification_report(y_test,predictions))
# Print the overall accuracy
print(metrics.accuracy_score(y_test,predictions))

"""### KNN"""

knn_classifier = Pipeline([('tfidf', TfidfVectorizer(stop_words=stopwords)),
                     ('clf', KNeighborsClassifier())])

knn_classifier.fit(X_train, y_train)
predictions = knn_classifier.predict(X_test)
# Print the overall accuracy, along with weighted precision, weighted recall and f1 scores
print("Accuracy by KNN Classifier is ")
print(metrics.accuracy_score(y_test,predictions)*100)
print("Weighted Precision by KNN Classifier is")
print(metrics.precision_score(y_test,predictions, average='weighted')*100)
print("Weighted Recall by KNN Classifier is ")
print(metrics.recall_score(y_test,predictions, average='weighted')*100)
print("F1 score by KNN Classifier is ")
print(metrics.f1_score(y_test,predictions, average='weighted')*100)

# Report the confusion matrix
print(metrics.confusion_matrix(y_test,predictions))
# Print a classification report
print(metrics.classification_report(y_test,predictions))
# Print the overall accuracy
print(metrics.accuracy_score(y_test,predictions))

"""### Random Forest"""

random_forest = Pipeline([('tfidf', TfidfVectorizer(stop_words=stopwords)),
                     ('clf', RandomForestClassifier())])

random_forest.fit(X_train, y_train)
predictions = random_forest.predict(X_test)
# Print the overall accuracy, along with weighted precision, weighted recall and f1 scores
print("Accuracy by Random Forest is ")
print(metrics.accuracy_score(y_test,predictions)*100)
print("Weighted Precision by Random Forest is")
print(metrics.precision_score(y_test,predictions, average='weighted')*100)
print("Weighted Recall by Random Forest is ")
print(metrics.recall_score(y_test,predictions, average='weighted')*100)
print("F1 score by Random Forest is ")
print(metrics.f1_score(y_test,predictions, average='weighted')*100)

# Report the confusion matrix
print(metrics.confusion_matrix(y_test,predictions))
# Print a classification report
print(metrics.classification_report(y_test,predictions))
# Print the overall accuracy
print(metrics.accuracy_score(y_test,predictions))

"""## Of all the four ML classifiers we used, Linear Support Vectorm Machine gave the highest accuracy of 97.78% 

###However, we must be vary that it might be a result of overfitting that might yield such high accuracy results. For the purpose of same, we perform the following one simple step for our confirmation - 

1. Calculation of K-fold Cross Validation with k=5 
"""

from sklearn.model_selection import cross_val_score

scores = cross_val_score(linear_svc,X, y, cv=5)
print("Accuracy = %0.3f with either plus/minus %0.3f" %(scores.mean(), scores.std()*3))

"""While the difference between the cross-validation accuracy and raw accuracy is around 2.98% which while is significant doesn't cause concern for overfitting. 
Besides, Linear Support Vector Machines, on an average, perform better than most of the ML classifiers in tasks of "Text Classification" and "Document Classification"

## Subtask 5. Identification of strategies that might improve the accuracy further

The following strategies might improve the accuracy further - 
1. Pre-processing with Word2Vec and utilizing Logistic Regression
2. Pre-processing with Doc2Vect and utilizing Logistic Regression
3. Pre-processing with Bag-of-Words and utilizing Keras

## Thank You.
"""